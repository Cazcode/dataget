from dataget.dataset import DataSet, SubSet
from dataget.utils import get_file, maybe_mkdir
import gzip
import os

TRAIN_FEATURES_URL = "http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz"
TRAIN_LABELS_URL = "http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz"
TEST_FEATURES_URL = "http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz"
TEST_LABELS_URL = "http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz"

def ungzip(src_name, dest_name):
    print("extracting {}".format(dest_name))

    with gzip.open(src_name, 'rb') as infile:
        with open(dest_name, 'wb') as outfile:
            for line in infile:
                outfile.write(line)


def arrays_to_images(path, images, labels, dims, format):
    from PIL import Image

    last = -1
    n = len(labels)

    for i, (array_img, label) in (images, labels) |*> zip |> enumerate:

        label = str(label)
        class_path = os.path.join(path, label) |> maybe_mkdir

        with Image.fromarray(array_img) as im:
            im = im.resize(dims)
            im.save(
                os.path.join(
                    class_path,
                    "{}.{}".format(i, format)
                ),
                quality=100
            )

        percent = int(float(i + 1) / n * 100)
        if percent % 10 == 0 and percent != last:
            print("{}%".format(percent))
            last = percent


class MNIST(DataSet):

    def __init__(self, *args, **kwargs):
        super(MNIST, self).__init__(*args, **kwargs)

        # self.path
        # self.training_set
        # self.training_set.path
        # self.test_set
        # self.test_set.path


    @property
    def training_set_class(self):
        return MNISTTrainingSet

    @property
    def test_set_class(self):
        return MNISTTestSet

    @property
    def help(self):
        return "" # information for the help command

    def reqs(self, **kwargs):
        return "idx2numpy pillow" # e.g. "numpy pandas pillow"

    def _download(self, **kwargs):
        get_file(TRAIN_FEATURES_URL, self.path, "train-features.gz")
        get_file(TRAIN_LABELS_URL, self.path, "train-labels.gz")
        get_file(TEST_FEATURES_URL, self.path, "test-features.gz")
        get_file(TEST_LABELS_URL, self.path, "test-labels.gz")

    def _extract(self, **kwargs):
        self.training_set.make_dirs()
        self.test_set.make_dirs()

        ungzip(
            os.path.join(self.path, "train-features.gz"),
            os.path.join(self.path, "train-features.idx")
        )

        ungzip(
            os.path.join(self.path, "train-labels.gz"),
            os.path.join(self.path, "train-labels.idx")
        )

        ungzip(
            os.path.join(self.path, "test-features.gz"),
            os.path.join(self.path, "test-features.idx")
        )

        ungzip(
            os.path.join(self.path, "test-labels.gz"),
            os.path.join(self.path, "test-labels.idx")
        )


    def _remove_compressed(self, **kwargs):
        # remove the compressed files
        print("removing compressed")
        os.path.join(self.path, "train-features.gz") |> os.remove
        os.path.join(self.path, "train-labels.gz") |> os.remove
        os.path.join(self.path, "test-features.gz") |> os.remove
        os.path.join(self.path, "test-labels.gz") |> os.remove

    def _process(self, dims="28x28", format="jpg", **kwargs):
        from idx2numpy import convert_from_file

        dims = dims.split('x')
        dims = tuple(map(int, dims))

        print("Image dims: {}, format: {}".format(dims, format))

        print("processing training-set")
        arrays_to_images(
            path = self.training_set.path,
            images = os.path.join(self.path, "train-features.idx") |> convert_from_file,
            labels = os.path.join(self.path, "train-labels.idx") |> convert_from_file,
            dims = dims,
            format = format
        )

        print("processing test-set")
        arrays_to_images(
            path = self.test_set.path,
            images = os.path.join(self.path, "test-features.idx") |> convert_from_file,
            labels = os.path.join(self.path, "test-labels.idx") |> convert_from_file,
            dims = dims,
            format = format
        )


    def _remove_raw(self, **kwargs):
        print("removing raw")
        os.path.join(self.path, "train-features.idx") |> os.remove
        os.path.join(self.path, "train-labels.idx") |> os.remove
        os.path.join(self.path, "test-features.idx") |> os.remove
        os.path.join(self.path, "test-labels.idx") |> os.remove




class SetBase(SubSet):

    def __init__(self, *args, **kwargs):
        super(SetBase, self).__init__(*args, **kwargs)
        self._dataframe = None
        self._features = None
        self._labels = None


    def _dict_generator(self):
        for root, dirs, files in os.walk(self.path):
            for file in files:
                if root != self.path:
                    class_id = root.split("/") |> .[-1]  |> int

                    yield dict(
                        filename = os.path.join(root, file),
                        class_id = class_id
                    )
        print("Done")

    def _load_dataframe(self):
        if self._dataframe is None:
            import pandas as pd
            self._dataframe = pd.DataFrame(self._dict_generator())


    def dataframe(self):
        from scipy.misc import imread

        self._load_dataframe()

        if not "image" in self._dataframe:
            self._dataframe["image"] = self._dataframe.filename.apply(imread)

        return self._dataframe


    def arrays(self):
        import numpy as np

        if self._features is None or self._labels is None:
            dataframe = self.dataframe()

            self._features = np.stack(dataframe.image.as_matrix())
            self._labels = np.stack(dataframe.class_id.as_matrix())

        return self._features, self._labels


    def random_batch_dataframe_generator(self, batch_size):
        from scipy.misc import imread

        self._load_dataframe()

        while True:
            batch = self._dataframe.sample(batch_size)

            if not "image" in batch:
                batch["image"] = batch.filename.apply(imread)

            yield batch


    def random_batch_arrays_generator(self, batch_size):
        import numpy as np

        for data in self.random_batch_dataframe_generator(batch_size):
            features = np.stack(data.image.as_matrix())
            labels = np.stack(data.class_id.as_matrix())

            yield features, labels


class MNISTTestSet(SetBase):

    def __init__(self, dataset):
        super(MNISTTestSet, self).__init__(dataset, "test-set")


class MNISTTrainingSet(SetBase):

    def __init__(self, dataset):
        super(MNISTTrainingSet, self).__init__(dataset, "training-set")
