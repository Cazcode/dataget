{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Dataget \u00b6 Dataget is an easy to use, framework-agnostic, dataset library that gives you quick access to a collection of Machine Learning datasets through a simple API. Main features: Minimal : Downloads entire datasets with just 1 line of code. Compatible : Loads data as numpy arrays or pandas dataframes which can be easily used with the majority of Machine Learning frameworks. Transparent : By default stores the data in your current project so you can easily inspect it. Memory Efficient : When a dataset doesn't fit in memory it will instead return the metadata needed so it can be iteratively loaded. Integrates with Kaggle : Supports loading Datasets directly from Kaggle in a variety of formats. Getting Started \u00b6 In dataget you just have to use two functions: data to specify source of the data. get to download the dataset to disk and load it into memory. import dataget as dg X_train , y_train , X_test , y_test = dg . data ( \"vision/mnist\" ) . get () This examples downloads the MNIST to ./data/vision_mnist and loads it as numpy arrays. Kaggle \u00b6 Kaggle promotes the use of csv files and dataget loves it! import dataget as dg df_train , df_test = dg . data ( \"kaggle\" , dataset = \"cristiangarcia/pointcloudmnist2d\" ) . get ( files = [ \"train.csv\" , \"test.csv\" ]) In the future we want to expand Kaggle support in the following ways: Be able to load any file that numpy or pandas can read. Have generic support for other types of datasets like images, audio, or video. E.g. dg.get(\"kaggle/vision\", ...).get(...) Installation \u00b6 Avaiable at pypi as dataget , you can install it with your favorite python package manager: # pip pip install dataget # pipenv pipenv install pytest # poetry poetry add dataget","title":"Introduction"},{"location":"#dataget","text":"Dataget is an easy to use, framework-agnostic, dataset library that gives you quick access to a collection of Machine Learning datasets through a simple API. Main features: Minimal : Downloads entire datasets with just 1 line of code. Compatible : Loads data as numpy arrays or pandas dataframes which can be easily used with the majority of Machine Learning frameworks. Transparent : By default stores the data in your current project so you can easily inspect it. Memory Efficient : When a dataset doesn't fit in memory it will instead return the metadata needed so it can be iteratively loaded. Integrates with Kaggle : Supports loading Datasets directly from Kaggle in a variety of formats.","title":"Dataget"},{"location":"#getting-started","text":"In dataget you just have to use two functions: data to specify source of the data. get to download the dataset to disk and load it into memory. import dataget as dg X_train , y_train , X_test , y_test = dg . data ( \"vision/mnist\" ) . get () This examples downloads the MNIST to ./data/vision_mnist and loads it as numpy arrays.","title":"Getting Started"},{"location":"#kaggle","text":"Kaggle promotes the use of csv files and dataget loves it! import dataget as dg df_train , df_test = dg . data ( \"kaggle\" , dataset = \"cristiangarcia/pointcloudmnist2d\" ) . get ( files = [ \"train.csv\" , \"test.csv\" ]) In the future we want to expand Kaggle support in the following ways: Be able to load any file that numpy or pandas can read. Have generic support for other types of datasets like images, audio, or video. E.g. dg.get(\"kaggle/vision\", ...).get(...)","title":"Kaggle"},{"location":"#installation","text":"Avaiable at pypi as dataget , you can install it with your favorite python package manager: # pip pip install dataget # pipenv pipenv install pytest # poetry poetry add dataget","title":"Installation"},{"location":"api/","text":"Reference API \u00b6","title":"Reference API"},{"location":"api/#reference-api","text":"","title":"Reference API"},{"location":"dataset/","text":"Creating a Dataset \u00b6 Dataset \u00b6 __init__ ( self , root ) \u00b6 Show source code in dataget/datasets/dataset.py 14 15 16 17 18 19 20 21 22 23 def __init__ ( self , root : Path ): \"\"\" ABC \"\"\" assert self . name , f \"Empty 'name' for class {self.__class__} \" if not isinstance ( root , Path ): root = Path ( root ) self . path = root / self . name . replace ( \"/\" , \"_\" ) ABC get ( self , use_cache = True , ** kwargs ) \u00b6 Show source code in dataget/datasets/dataset.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def get ( self , use_cache = True , ** kwargs ): \"\"\" DFG \"\"\" if not self . is_valid ( ** kwargs ) or not use_cache : shutil . rmtree ( self . path , ignore_errors = True ) self . path . mkdir ( parents = True ) # get data coro = self . download ( ** kwargs ) if coro is not None : asyncio . get_event_loop () . run_until_complete ( coro ) if not self . is_valid ( ** kwargs ): raise DownloadError ( f \"Failed download for ' {self.name} ' at ' {self.path} '\" ) return self . load_data ( ** kwargs ) DFG","title":"Creating a Dataset"},{"location":"dataset/#creating-a-dataset","text":"","title":"Creating a Dataset"},{"location":"dataset/#dataget.datasets.dataset.Dataset","text":"","title":"Dataset"},{"location":"dataset/#dataget.datasets.dataset.Dataset.__init__","text":"Show source code in dataget/datasets/dataset.py 14 15 16 17 18 19 20 21 22 23 def __init__ ( self , root : Path ): \"\"\" ABC \"\"\" assert self . name , f \"Empty 'name' for class {self.__class__} \" if not isinstance ( root , Path ): root = Path ( root ) self . path = root / self . name . replace ( \"/\" , \"_\" ) ABC","title":"__init__()"},{"location":"dataset/#dataget.datasets.dataset.Dataset.get","text":"Show source code in dataget/datasets/dataset.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def get ( self , use_cache = True , ** kwargs ): \"\"\" DFG \"\"\" if not self . is_valid ( ** kwargs ) or not use_cache : shutil . rmtree ( self . path , ignore_errors = True ) self . path . mkdir ( parents = True ) # get data coro = self . download ( ** kwargs ) if coro is not None : asyncio . get_event_loop () . run_until_complete ( coro ) if not self . is_valid ( ** kwargs ): raise DownloadError ( f \"Failed download for ' {self.name} ' at ' {self.path} '\" ) return self . load_data ( ** kwargs ) DFG","title":"get()"},{"location":"datasets/kaggle/","text":"","title":"Kaggle"},{"location":"datasets/vision/mnist/","text":"","title":"MNIST"}]}